{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API demonstration for paper of v1.0\n",
    "\n",
    "_the LSST-DESC CLMM team_\n",
    "\n",
    "\n",
    "Here we demonstrate how to use `clmm` to estimate a WL halo mass from observations of a galaxy cluster when source galaxies follow a given distribution (the Chang. (2013) implemented in `clmm`). It uses several functionalities of the support `mock_data` module to produce mock datasets.\n",
    "\n",
    "- Setting things up, with the proper imports.\n",
    "- Computing the binned reduced tangential shear profile, for the 2 datasets, using logarithmic binning.\n",
    "- Setting up a model accounting for the redshift distribution.\n",
    "- Perform a simple fit using `scipy.optimize.curve_fit` and visualize the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import some standard packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.rcParams['font.family'] = ['gothambook','gotham','gotham-book','serif']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we import `clmm`'s core modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clmm\n",
    "import clmm.dataops as da\n",
    "import clmm.galaxycluster as gc\n",
    "import clmm.theory as theory\n",
    "import clmm.support.mock_data as mock\n",
    "from clmm.utils import convert_units\n",
    "from clmm import Cosmology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring shear profiles "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`clmm` has a support code to generate a mock catalog given a input cosmology and cluster parameters. We will use this to generate a data sample to be used in this example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(14) # For reproducibility\n",
    "\n",
    "# Set cosmology of mock data\n",
    "cosmo = Cosmology(H0=70.0, Omega_dm0=0.27-0.045, Omega_b0=0.045, Omega_k0=0.0)\n",
    "\n",
    "# Cluster info\n",
    "cluster_m = 1.e15 # Cluster mass - ($M200_m$) [Msun]\n",
    "concentration = 4  # Cluster concentration\n",
    "cluster_z = 0.3 # Cluster redshift\n",
    "cluster_ra = 0. # Cluster Ra in deg\n",
    "cluster_dec = 0. # Cluster Dec in deg\n",
    "\n",
    "# Make mock galaxies\n",
    "mock_galaxies = mock.generate_galaxy_catalog(\n",
    "    cluster_m=cluster_m, cluster_z=cluster_z, cluster_c=concentration, # Cluster data\n",
    "    cosmo=cosmo, # Cosmology object\n",
    "    zsrc='chang13', # Galaxy redshift distribution, \n",
    "    zsrc_min=0.6, # Minimum redshift of the galaxies\n",
    "    shapenoise=0.05, # Gaussian shape noise to the galaxy shapes\n",
    "    photoz_sigma_unscaled=0.05, # Photo-z errors to source redshifts\n",
    "    ngals=10000 # Number of galaxies to be generated\n",
    ")['ra', 'dec', 'e1', 'e2', 'z', 'ztrue', 'pzbins', 'pzpdf', 'id']\n",
    "print(f'This results in a table with the columns: {\", \".join(mock_galaxies.colnames)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extract the column of this mock catalog to show explicitely how the quantities can be used on `clmm` functionality and how to add them to a `GalaxyCluster` object: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put galaxy values on arrays\n",
    "gal_ra = mock_galaxies['ra'] # Galaxies Ra in deg\n",
    "gal_dec = mock_galaxies['dec'] # Galaxies Dec in deg\n",
    "gal_e1 = mock_galaxies['e1'] # Galaxies elipticipy 1\n",
    "gal_e2 = mock_galaxies['e2'] # Galaxies elipticipy 2\n",
    "gal_z = mock_galaxies['z'] # Galaxies observed redshift\n",
    "gal_ztrue = mock_galaxies['ztrue'] # Galaxies true redshift\n",
    "gal_pzbins = mock_galaxies['pzbins'] # Galaxies P(z) bins  \n",
    "gal_pzpdf = mock_galaxies['pzpdf'] # Galaxies P(z)\n",
    "gal_id = mock_galaxies['id'] # Galaxies ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the source galaxy quantities, we can compute the elepticities and corresponding radial profile usimg `clmm.dataops` functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert elipticities into shears\n",
    "gal_ang_dist, gal_gt, gal_gx = da.compute_tangential_and_cross_components(cluster_ra, cluster_dec,\n",
    "                                                                          gal_ra, gal_dec,\n",
    "                                                                          gal_e1, gal_e2,\n",
    "                                                                          geometry=\"flat\")\n",
    "\n",
    "# Measure profile\n",
    "profile = da.make_radial_profile([gal_gt, gal_gx, gal_z],\n",
    "                                 gal_ang_dist, \"radians\", \"Mpc\",\n",
    "                                 bins=da.make_bins(0.01, 3.7, 50),\n",
    "                                 cosmo=cosmo,\n",
    "                                 z_lens=cluster_z,\n",
    "                                 include_empty_bins=False)\n",
    "print(f'Profile table has columns: {\", \".join(profile.colnames)},')\n",
    "print('where p_(0, 1, 2) = (gt, gx, z)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other possibility is to use the `GalaxyCluster` object. For that you just have to provide the following information of the cluster:\n",
    "\n",
    "* Ra, Dec [deg]\n",
    "* Mass - ($M200_m$) [Msun]\n",
    "* Concentration\n",
    "* Redshift\n",
    "\n",
    "\n",
    "and the source galaxies:\n",
    "\n",
    "* Ra, Dec [deg]\n",
    "* 2 axis of eliptticities\n",
    "* Redshift\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a GCData with the galaxies\n",
    "galaxies = clmm.GCData()\n",
    "galaxies['ra'] = gal_ra\n",
    "galaxies['dec'] = gal_dec\n",
    "galaxies['e1'] = gal_e1\n",
    "galaxies['e2'] = gal_e2\n",
    "galaxies['z'] = gal_z\n",
    "galaxies['ztrue'] = gal_ztrue\n",
    "galaxies['pzbins'] = gal_pzbins\n",
    "galaxies['pzpdf'] = gal_pzpdf\n",
    "galaxies['id'] = gal_id\n",
    "\n",
    "# Create a GalaxyCluster\n",
    "cluster = clmm.GalaxyCluster(\"Name of cluster\", cluster_ra, cluster_dec,\n",
    "                                   cluster_z, galaxies)\n",
    "\n",
    "# Convert elipticities into shears for the members\n",
    "cluster.compute_tangential_and_cross_components(geometry=\"flat\")\n",
    "print(cluster.galcat.colnames)\n",
    "\n",
    "# Measure profile and add profile table to the cluster\n",
    "cluster.make_radial_profile(bins=da.make_bins(0.1, 6, 25, method='evenlog10width'),\n",
    "                            bin_units=\"Mpc\",\n",
    "                            cosmo=cosmo,\n",
    "                            include_empty_bins=False,\n",
    "                            gal_ids_in_bins=True,\n",
    "                           )\n",
    "print(cluster.profile.colnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This resoults in an attribute `table` added to the `cluster` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paper_formating import prep_plot\n",
    "prep_plot(figsize=(9, 9))\n",
    "errorbar_kwargs = dict(linestyle='', marker='o',\n",
    "    markersize=1, elinewidth=.5, capthick=.5)\n",
    "plt.errorbar(cluster.profile['radius'], cluster.profile['gt'],\n",
    "             cluster.profile['gt_err'], c='k', **errorbar_kwargs)\n",
    "plt.xlabel('r [Mpc]', fontsize = 10)\n",
    "plt.ylabel(r'$g_t$', fontsize = 10)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theoretical predictions\n",
    "\n",
    "We consider 3 models:\n",
    "1. One model where all sources are considered at the same redshift\n",
    "2. One model using the overall source redshift distribution to predict the reduced tangential shear\n",
    "3. A more accurate model, relying on the fact that we have access to the individual redshifts of the sources, where the average reduced tangential shear is averaged independently in each bin, accounting for the acutal population of sources in each bin.\n",
    "\n",
    "All models rely on `clmm.predict_reduced_tangential_shear` to make a prediction that accounts for the redshift distribution of the galaxies in each radial bin:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model considering all sources located at the average redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_reduced_tangential_shear_mean_z(profile, logm):\n",
    "    return clmm.compute_reduced_tangential_shear(\n",
    "            r_proj=profile['radius'], # Radial component of the profile\n",
    "            mdelta=10**logm, # Mass of the cluster [M_sun]\n",
    "            cdelta=4, # Concentration of the cluster\n",
    "            z_cluster=cluster_z, # Redshift of the cluster\n",
    "            z_source=np.mean(cluster.galcat['z']), # Mean value of source galaxies redshift\n",
    "            cosmo=cosmo,\n",
    "            delta_mdef=200,\n",
    "            halo_profile_model='nfw'\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model relying on the overall redshift distribution of the sources, not using individual redshift information, i.e. approximate  (from Applegate et al. 2014, MNRAS, 439, 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_inf = 1000\n",
    "dl_inf = cosmo.eval_da_z1z2(cluster_z, z_inf)\n",
    "d_inf = cosmo.eval_da(z_inf)\n",
    "\n",
    "def betas(z):\n",
    "    dls = cosmo.eval_da_z1z2(cluster_z, z)\n",
    "    ds = cosmo.eval_da(z)\n",
    "    return dls * d_inf / (ds * dl_inf)\n",
    "\n",
    "def predict_reduced_tangential_shear_approx(profile, logm):\n",
    "\n",
    "    bs_mean = np.mean(betas(cluster.galcat['z']))\n",
    "    bs2_mean = np.mean(betas(cluster.galcat['z'])**2)\n",
    "\n",
    "    gamma_t_inf = clmm.compute_tangential_shear(\n",
    "            r_proj=profile['radius'], # Radial component of the profile\n",
    "            mdelta=10**logm, # Mass of the cluster [M_sun]\n",
    "            cdelta=4, # Concentration of the cluster\n",
    "            z_cluster=cluster_z, # Redshift of the cluster\n",
    "            z_source=z_inf, # Redshift value at infinity\n",
    "            cosmo=cosmo,\n",
    "            delta_mdef=200,\n",
    "            halo_profile_model='nfw')\n",
    "    convergence_inf = clmm.compute_convergence(\n",
    "            r_proj=profile['radius'], # Radial component of the profile\n",
    "            mdelta=10**logm, # Mass of the cluster [M_sun]\n",
    "            cdelta=4, # Concentration of the cluster\n",
    "            z_cluster=cluster_z, # Redshift of the cluster\n",
    "            z_source=z_inf, # Redshift value at infinity\n",
    "            cosmo=cosmo,\n",
    "            delta_mdef=200,\n",
    "            halo_profile_model='nfw')\n",
    "        \n",
    "    return bs_mean*gamma_t_inf/(1-(bs2_mean/bs_mean)*convergence_inf)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model using individual redshift and radial information, to compute the averaged shear in each radial bin, based on the galaxies actually present in that bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.galcat['theta_mpc'] = convert_units(\n",
    "    cluster.galcat['theta'], 'radians', 'mpc',\n",
    "    cluster.z, cosmo)\n",
    "def predict_reduced_tangential_shear_exact(profile, logm):\n",
    "    return np.array([np.mean(\n",
    "        clmm.compute_reduced_tangential_shear(\n",
    "            # Radial component of each source galaxy inside the radial bin\n",
    "            r_proj=cluster.galcat[radial_bin['gal_id']]['theta_mpc'],\n",
    "            mdelta=10**logm, # Mass of the cluster [M_sun]\n",
    "            cdelta=4, # Concentration of the cluster\n",
    "            z_cluster=cluster_z, # Redshift of the cluster\n",
    "            # Redshift value of each source galaxy inside the radial bin\n",
    "            z_source=cluster.galcat[radial_bin['gal_id']]['z'],\n",
    "            cosmo=cosmo,\n",
    "            delta_mdef=200,\n",
    "            halo_profile_model='nfw'\n",
    "        )) for radial_bin in profile])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mass fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We estimate the best-fit mass using `scipy.optimize.curve_fit`.  We compare estimated mass for noisy and ideal data, using both models described above (naive with average redshift or the model taking into account the redshift distribution). The choice of fitting $\\log_{10} M$ instead of $M$ lowers the range of pre-defined fitting bounds from several order of magnitude for the mass to unity. From the associated error $\\Delta (\\log_{10}M)$ we calculate the error to mass as $\\Delta M = M_{fit}\\log(10)\\Delta (\\log_{10}M)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clmm.support.sampler import fitters\n",
    "def fit_mass(predict_function):\n",
    "    popt, pcov = fitters['curve_fit'](predict_function,\n",
    "        cluster.profile, \n",
    "        cluster.profile['gt'], \n",
    "        cluster.profile['gt_err'], bounds=[10.,17.])\n",
    "    logm, logm_err = popt[0], np.sqrt(pcov[0][0])\n",
    "    return {'logm':logm, 'logm_err':logm_err,\n",
    "            'm': 10**logm, 'm_err': (10**logm)*logm_err*np.log(10)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_mean_z = fit_mass(predict_reduced_tangential_shear_mean_z)\n",
    "fit_approx = fit_mass(predict_reduced_tangential_shear_approx)\n",
    "fit_exact = fit_mass(predict_reduced_tangential_shear_exact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The input mass = {cluster_m:.2e} Msun\\n')\n",
    "\n",
    "print(f'Best fit mass for average redshift = {fit_mean_z[\"m\"]:.2e} +/- {fit_mean_z[\"m_err\"]:.2e} Msun')\n",
    "print(f'Best fit mass for Applegate 2014 = {fit_approx[\"m\"]:.2e} +/- {fit_approx[\"m_err\"]:.2e} Msun')\n",
    "print(f'Best fit mass for exact redshift and radius = {fit_exact[\"m\"]:.2e} +/- {fit_exact[\"m_err\"]:.2e} Msun')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the reconstructed mass is biased when the redshift distribution is not accounted for in the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For visualization purpose, we calculate the reduced tangential shear predicted by the model with estimated masses for noisy and ideal data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predicted_shear(predict_function, fit_values):\n",
    "    gt_est = predict_function(cluster.profile, fit_values['logm'])\n",
    "    gt_est_err = [predict_function(cluster.profile, fit_values['logm']+i*fit_values['logm_err'])\n",
    "                          for i in (-3, 3)]\n",
    "    return gt_est, gt_est_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_mean_z, gt_err_mean_z =  get_predicted_shear(predict_reduced_tangential_shear_mean_z, fit_mean_z)\n",
    "gt_approx, gt_err_approx =  get_predicted_shear(predict_reduced_tangential_shear_approx, fit_approx)\n",
    "gt_exact, gt_err_exact =  get_predicted_shear(predict_reduced_tangential_shear_exact, fit_exact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compare to tangential shear obtained with theoretical mass. We plot the reduced tangential shear models first when redshift distribution is accounted for in the model then for the naive approach, with respective best-fit masses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import MultipleLocator\n",
    "prep_plot(figsize=(9 , 9))\n",
    "gt_ax = plt.axes([.25, .42, .7, .55])\n",
    "\n",
    "gt_ax.errorbar(cluster.profile['radius'], cluster.profile['gt'], cluster.profile['gt_err'],\n",
    "             c='k', label=rf'$M_{{input}} = {cluster_m*1e-15}\\times10^{{{15}}} M_\\odot$',\n",
    "            **errorbar_kwargs)\n",
    "pow10 = 15\n",
    "mlabel = lambda name, fits: fr'$M_{{fit}}^{{{name}}} = {fits[\"m\"]/10**pow10:.2f}\\pm{fits[\"m_err\"]/10**pow10:.2f}\\times 10^{{{pow10}}} M_\\odot$'\n",
    "gt_ax.loglog(cluster.profile['radius'], gt_mean_z,'-g', \n",
    "           label=mlabel('avg(z)', fit_mean_z),\n",
    "          lw=.5)\n",
    "gt_ax.fill_between(cluster.profile['radius'], *gt_err_mean_z, lw=0, color='g', alpha=.3)\n",
    "\n",
    "gt_ax.loglog(cluster.profile['radius'], gt_approx,'-r', \n",
    "           label=mlabel('approx', fit_approx),\n",
    "             lw=.5)\n",
    "gt_ax.fill_between(cluster.profile['radius'], *gt_err_approx, lw=0, color='r', alpha=.3)\n",
    "\n",
    "gt_ax.loglog(cluster.profile['radius'], gt_exact,'-b', \n",
    "           label=mlabel('exact', fit_exact),\n",
    "             lw=.5)\n",
    "gt_ax.fill_between(cluster.profile['radius'], *gt_err_exact, lw=0, color='b', alpha=.3)\n",
    "\n",
    "\n",
    "\n",
    "gt_ax.set_ylabel(r'$g_t$', fontsize = 10)\n",
    "gt_ax.legend(fontsize=6)\n",
    "gt_ax.set_xticklabels([])\n",
    "\n",
    "res_ax = plt.axes([.25, .2, .7, .2])\n",
    "delta = (cluster.profile['radius'][1]/cluster.profile['radius'][0])**.15\n",
    "res_ax.errorbar(cluster.profile['radius']/delta,\n",
    "                gt_mean_z/cluster.profile['gt']-1,\n",
    "                cluster.profile['gt_err']/cluster.profile['gt'],\n",
    "                c='g', **errorbar_kwargs)\n",
    "res_ax.errorbar(cluster.profile['radius'],\n",
    "                gt_approx/cluster.profile['gt']-1,\n",
    "                cluster.profile['gt_err']/cluster.profile['gt'],\n",
    "                c='r', **errorbar_kwargs)\n",
    "res_ax.errorbar(cluster.profile['radius']*delta,\n",
    "                gt_exact/cluster.profile['gt']-1,\n",
    "                cluster.profile['gt_err']/cluster.profile['gt'],\n",
    "                c='b', **errorbar_kwargs)\n",
    "res_ax.set_xlabel('$R$ [Mpc]', fontsize = 10)\n",
    "res_ax.set_ylabel(r'$(g_t^{model}-g_t^{data})/g_t^{data}$', fontsize = 10)\n",
    "res_ax.set_ylabel(r'$\\frac{g_t^{model}-g_t^{data}}{g_t^{data}}$', fontsize = 10)\n",
    "res_ax.set_xscale('log')\n",
    "res_ax.set_xlim(gt_ax.get_xlim())\n",
    "#res_ax.yaxis.set_major_locator(MultipleLocator(.04))\n",
    "#res_ax.yaxis.set_minor_locator(MultipleLocator(.02))\n",
    "\n",
    "for p in (gt_ax, res_ax):\n",
    "    p.xaxis.grid(True, which='major', lw=.5)\n",
    "    p.yaxis.grid(True, which='major', lw=.5)\n",
    "    p.xaxis.grid(True, which='minor', lw=.1)\n",
    "    p.yaxis.grid(True, which='minor', lw=.1)\n",
    "\n",
    "plt.savefig('r_gt.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda-clmmenv",
   "language": "python",
   "name": "conda-clmmenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
